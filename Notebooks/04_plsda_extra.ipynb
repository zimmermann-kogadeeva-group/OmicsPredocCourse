{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1019ce47-d4be-48d7-8967-0c792906c07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "\n",
    "def separate(data, col, into, sep=\"_\", **kwargs):\n",
    "    return data.assign(\n",
    "        **data.get(col).str.split(sep, expand=True, **kwargs)\n",
    "        .rename(columns={i: x for i, x in enumerate(into)})\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b0c684-2d4d-458e-907b-614dfa49da45",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1381bbf-a7a3-4cf3-a8da-dcfcea8d04dc",
   "metadata": {},
   "source": [
    "As in the previous notebook, we first load the normalised counts from DESeq2 analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a821ed25-59d5-458d-bacc-8b0203ec9a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = pd.read_csv(\"../Output/DESeq2/normalised_counts.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1445893b-9f6a-4d13-9587-a118d541dbc1",
   "metadata": {},
   "source": [
    "and load the MIC values and we create additional columns for level of \n",
    "antibiotic resistence for both antibiotics (0 for low ABR and 1 for high ABR):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6e1d24-03ac-4cdb-8b6b-c63cea09f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_threshold = 30\n",
    "df_mic = (\n",
    "    pd.read_csv(\"../Data/mic.csv\", dtype={\"strain\": str})\n",
    "    .assign(\n",
    "        cza_mic_level=lambda x: (x.cza_mic > mic_threshold).astype(int),\n",
    "        mem_mic_level=lambda x: (x.mem_mic > mic_threshold).astype(int)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228644cc-5028-4483-a66e-dde9e1004a86",
   "metadata": {},
   "source": [
    "## Leave-one-out models\n",
    "\n",
    "To test the generalizability of the models, we performed a leave-one-strain-out analysis, \n",
    "where each of the models was trained on the data from six strains (45 samples) and tested \n",
    "on the data from the sixth strain not included in the training (9 samples).\n",
    "\n",
    "First, we transform the dataframe to the correcto format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4faf34-43a8-4f03-bcf0-03d246d91094",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm_rot = (\n",
    "    df_norm\n",
    "    .transpose()\n",
    "    .reset_index(names=\"sample\")\n",
    "    .pipe(separate, \"sample\", [\"strain\", \"condition\", \"replicate\"], sep=\"_\")\n",
    "    .merge(df_mic, on=[\"strain\", \"condition\"], how=\"left\")\n",
    ")\n",
    "df_norm_rot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed1f35e-4d33-4c37-85de-fdeaae9b0f8b",
   "metadata": {},
   "source": [
    "As in the previous notebook, we fit the models to the data, but this time we leave data related to one strain per each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b83a798-b488-49ca-95d5-fcb8b0e15525",
   "metadata": {},
   "outputs": [],
   "source": [
    "strains = [\"083.2\", \"090.3\", \"095.3\", \"678.3\", \"804.2\", \"816.3\"]\n",
    "meta_cols = [\"sample\", \"strain\", \"condition\", \"replicate\", \"cza_mic\", \"mem_mic\", \"cza_mic_level\", \"mem_mic_level\"]\n",
    "models = {strain: PLSRegression(n_components=2) for strain in strains}\n",
    "\n",
    "factors = {}\n",
    "\n",
    "for strain, model in models.items():\n",
    "    train_data = df_norm_rot.query(\"strain != @strain\")\n",
    "    x_train = train_data.drop(columns=meta_cols).to_numpy()\n",
    "    y_train = train_data.mem_mic_level.to_numpy()\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    factors[strain] = model.transform(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2873a375-bcc5-4ab2-9e15-de1fbd11aec9",
   "metadata": {},
   "source": [
    "We can combine all the factor values from each model in one dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f625e7d-994e-44ea-9934-d13da7a2fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pls = pd.concat([\n",
    "    pd.DataFrame(factor_vals[0], columns=[\"Factor1\", \"Factor2\"])\n",
    "    .join(\n",
    "        df_norm_rot\n",
    "        .query(\"strain != @strain\")\n",
    "        .get(meta_cols)\n",
    "        .reset_index(drop=True)\n",
    "    ).assign(strain_left=strain)\n",
    "    for strain, factor_vals in factors.items()\n",
    "], ignore_index=True)\n",
    "df_pls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef69c5-14b5-4850-ba8d-f5f181e38204",
   "metadata": {},
   "source": [
    "and plot those below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a7a955-fe61-41e8-8052-8e689c40ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = (\n",
    "    sns.FacetGrid(\n",
    "        df_pls.replace({\"mem_mic_level\": {0: \"low\", 1: \"high\"}}), \n",
    "        col=\"strain_left\", \n",
    "        col_wrap=3\n",
    "    )\n",
    "    .map_dataframe(\n",
    "        sns.scatterplot,\n",
    "        x=\"Factor1\",\n",
    "        y=\"Factor2\",\n",
    "        style=\"condition\", \n",
    "        hue=\"mem_mic_level\",\n",
    "    )\n",
    "    .set(xlim=(-55, 55))\n",
    "    .set_titles(col_template=\"{col_name}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3e74b1-bf51-472e-811f-0cc23748d01c",
   "metadata": {},
   "source": [
    "We calculate the accuracy scores for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc6d6e7-4d1b-4d4a-92f8-389aaeca6e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for strain, model in models.items():\n",
    "    data = df_norm_rot.query(\"strain == @strain\")\n",
    "    x = data.drop(columns=meta_cols).to_numpy()\n",
    "    y = data.mem_mic_level.to_numpy()\n",
    "    y_pred = [1 if y > 0.5 else 0 for y in model.predict(x)]\n",
    "    scores[strain] = accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b8ede8-6bf4-4545-a5f4-e4ba5f78b10c",
   "metadata": {},
   "source": [
    "We convert the above dictionary to a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4ab25-7302-40c3-b6d4-241a7385661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accuracy = (\n",
    "    pd.DataFrame\n",
    "    .from_dict(scores, orient=\"index\", columns=[\"accuracy\"])\n",
    "    .reset_index(names=\"strain_left\")\n",
    ")\n",
    "df_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e323aa-76d1-4448-a72e-e8e3a4408b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(df_accuracy, y=\"accuracy\")\n",
    "sns.swarmplot(df_accuracy, y=\"accuracy\", hue=\"strain_left\")\n",
    "sns.move_legend(ax, loc=\"center left\", bbox_to_anchor=(0.9, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4870329-c24a-4b4e-b478-ae91f7d8b36d",
   "metadata": {},
   "source": [
    "**Tasks:** \n",
    "- can you determine what the top features have in common for these model?\n",
    "- which features are in common between models?\n",
    "- try to fit the other antibiotic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
